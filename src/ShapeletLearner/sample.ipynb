{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Implementation of Shapelets for RIGHT_ELBOW_ANGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Havent really used it but eh\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "## Data Imports\n",
    "from preprocess.features import *\n",
    "from preprocess.timeseries import *\n",
    "from preprocess.utils import *\n",
    "\n",
    "## Model Imports\n",
    "from model.shaplet_learner import *\n",
    "from utils.config import *\n",
    "from utils.trainer import *\n",
    "from utils.weight_init import *\n",
    "from ShapeletLearner.datasets.tsdataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.abspath(os.path.join(ROOT, \"..\", \"..\" )), \"P0001_shooting_alt.csv\") \n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RIGHT_ELBOW_ANGLE'] = data.apply(lambda row: angle_finder_shared(A = np.array([row['R_SHOULDER_x'], row['R_SHOULDER_y'], row['R_SHOULDER_z']]), \n",
    "                                                                       B = np.array([row['R_ELBOW_x'], row['R_ELBOW_y'], row['R_ELBOW_z']]), \n",
    "                                                                       C = np.array([row['R_WRIST_x'], row['R_WRIST_y'], row['R_WRIST_z']]), \n",
    "                                                                       D = np.array([row['R_ELBOW_x'], row['R_ELBOW_y'], row['R_ELBOW_z']])), axis=1)\n",
    "ts_data, labels = DatasetTimeseries(data, 'RIGHT_ELBOW_ANGLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "\n",
    "import torch\n",
    "\n",
    "def DTW_calc(ts1, ts2):\n",
    "    \"\"\"\n",
    "    Computes the DTW similarity (for univariate time series) between two time series.\n",
    "    Handles one input having batch size 1 for broadcasting (shapelet of shape (1, len_shapelet)).\n",
    "    \n",
    "    Parameters:\n",
    "    ts1: Tensor of shape (batch_size1, time_steps1) or (1, time_steps1) (shapelet)\n",
    "    ts2: Tensor of shape (batch_size2, time_steps2) (time series segment)\n",
    "    \n",
    "    Returns:\n",
    "    dtw_dist: Tensor of shape (batch_size,) containing the DTW distance for each batch.\n",
    "    \"\"\"\n",
    "    # Compute the cost matrix\n",
    "    cost_mat = cost_matrix(ts1, ts2)\n",
    "\n",
    "    # Return the square root of the final element in the cost matrix (total DTW cost for each batch)\n",
    "    return torch.sqrt(cost_mat[:, -1, -1])\n",
    "\n",
    "def euclidean_diff(ts1, ts2):\n",
    "    \"\"\"\n",
    "    Calculates the squared Euclidean distance between two points (or vectors) from two univariate time series.\n",
    "    Handles broadcasting if one input has batch size 1 (shapelet of shape (1,)).\n",
    "    \n",
    "    Parameters:\n",
    "    ts1: Tensor of shape (batch_size,)\n",
    "    ts2: Tensor of shape (batch_size,) or (1,)\n",
    "    \n",
    "    Returns:\n",
    "    dist: Tensor of shape (batch_size,) containing the squared Euclidean distance for each batch.\n",
    "    \"\"\"\n",
    "    return (ts1 - ts2) ** 2\n",
    "\n",
    "def cost_matrix(ts1, ts2):\n",
    "    \"\"\"\n",
    "    Computes the cost matrix for DTW with differentiable operations.\n",
    "    Handles one input having batch size 1 (for shapelet broadcasting), supports univariate time series.\n",
    "    \n",
    "    Parameters:\n",
    "    ts1: Tensor of shape (batch_size, time_steps1) or (1, time_steps1)\n",
    "    ts2: Tensor of shape (batch_size, time_steps2)\n",
    "    \n",
    "    Returns:\n",
    "    cum_sum: Tensor of shape (batch_size, time_steps1, time_steps2) containing the cumulative sum for each batch.\n",
    "    \"\"\"\n",
    "    batch_size1, ts1_size = ts1.shape \n",
    "    batch_size2, ts2_size = ts2.shape\n",
    "\n",
    "\n",
    "    batch_size = max(batch_size1, batch_size2)\n",
    "\n",
    "\n",
    "    cum_sum = torch.zeros((batch_size, ts1_size + 1, ts2_size + 1), device=ts1.device)\n",
    "    cum_sum[:, 1:, 0] = float('inf')\n",
    "    cum_sum[:, 0, 1:] = float('inf')\n",
    "\n",
    "\n",
    "    for i in range(1, ts1_size + 1):\n",
    "        for j in range(1, ts2_size + 1):\n",
    "            cost = euclidean_diff(ts1[:, i - 1], ts2[:, j - 1])\n",
    "            cum_sum[:, i, j] = cost + torch.min(torch.stack([\n",
    "                cum_sum[:, i - 1, j],   # Insertion\n",
    "                cum_sum[:, i, j - 1],   # Deletion\n",
    "                cum_sum[:, i - 1, j - 1]  # Match\n",
    "            ], dim=0), dim=0)[0]\n",
    "\n",
    "    return cum_sum[:, 1:, 1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapletLearner(nn.Module):\n",
    "    def __init__(self, num_shapelet, len_shapelet, input_size, num_classes, alpha_precision, kmeans_centroids, type_dist):\n",
    "        super().__init__()\n",
    "\n",
    "        assert input_size % len_shapelet  == 0, \"The input size may not be compatiable with the Timeseries size\"\n",
    "        assert type_dist in [\"euclid\", \"DTW\"]\n",
    "         \n",
    "        self.L = num_shapelet ## Using the paper's terminalogy\n",
    "        self.K = len_shapelet\n",
    "\n",
    "        self.Q = input_size\n",
    "        self.I = num_classes\n",
    "\n",
    "        self.alpha = alpha_precision\n",
    "        self.type_dist = type_dist\n",
    "\n",
    "        if kmeans_centroids is not None: ## TODO Include method directly\n",
    "            assert kmeans_centroids.shape == (num_shapelet, len_shapelet), \\\n",
    "                \"KMeans centroids must have the shape (num_shapelets, len_shapelet).\"\n",
    "            self.shapelets = nn.ParameterList(\n",
    "                [nn.Parameter(torch.tensor(centroid, dtype=torch.float32).unsqueeze(0)) for centroid in kmeans_centroids]\n",
    "            )\n",
    "        else:\n",
    "            self.shapelets = nn.ParameterList(nn.Parameter(torch.randn(self.K)) for _ in range(num_shapelet))\n",
    "        \n",
    "       \n",
    "        self.fc1 = nn.Linear(self.L, 2)\n",
    "\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss() ## This is what they used not sure why not BCE with logit but eh\n",
    "\n",
    "    def _compute_shapelet_dist(self, ts):\n",
    "        print(ts.shape)\n",
    "\n",
    "        shapelet_distances = [] \n",
    "        if self.type_dist == \"euclid\":\n",
    "\n",
    "            for shapelet in self.shapelets:\n",
    "                num_segments = self.Q - self.K + 1\n",
    "                distances = []\n",
    "                for j in range(num_segments):\n",
    "                    segment = ts[:, j:j+self.K] \n",
    "                    segment = segment\n",
    "                    dist = torch.mean((segment - shapelet)**2, dim = 1)\n",
    "                    if torch.isnan(dist).any():\n",
    "                        print(\"NaN detected in distance calculation\")\n",
    "                    distances.append(dist)\n",
    "                distances = torch.stack(distances, dim = 1)\n",
    "\n",
    "                hard_min, _ = torch.min(distances, dim=1)\n",
    "                if torch.isnan(hard_min).any():\n",
    "                    print(\"NaN detected in min operation\") \n",
    "                shapelet_distances.append(hard_min)\n",
    "\n",
    "\n",
    "            result =  torch.stack(shapelet_distances, dim = 1) \n",
    "        \n",
    "        \n",
    "        elif self.type_dist == \"DTW\":\n",
    "            for shapelet in self.shapelets:\n",
    "                num_segments = self.Q - self.K + 1\n",
    "                distances = []\n",
    "                for j in range(num_segments):\n",
    "                    segment = ts[:, j:j+self.K]\n",
    "                    dist = DTW_calc(segment, shapelet)\n",
    "                    if torch.isnan(dist).any():\n",
    "                        print(\"Nan Detected in DTW distance calculation\")\n",
    "                    distances.append(dist)\n",
    "                distances = torch.stack(distances, dim=1)\n",
    "                hard_min, _ = torch.min(distances, dim=1)\n",
    "                if torch.isnan(hard_min).any():\n",
    "                    print(\"NaN detected in DTW min\")\n",
    "                shapelet_distances.append(hard_min)\n",
    "\n",
    "            \n",
    "            result = torch.stack(shapelet_distances, dim=1)\n",
    "        return result\n",
    "\n",
    "    def forward(self, ts):\n",
    "        ts = ts.float()\n",
    "        shaplet_distances = self._compute_shapelet_dist(ts)\n",
    "        print(\"shapelet distance shape:\", shaplet_distances.shape)\n",
    "        output = self.fc1(shaplet_distances)\n",
    "        print(output.shape)\n",
    "        return output\n",
    "    \n",
    "    def loss(self, pred, labels):\n",
    "        return self.loss_fn(pred, labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shaplet_model(model, train_loader, optimizer, epochs = 10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for time_series, labels in train_loader:\n",
    "            time_series, labels = time_series.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(time_series)\n",
    "            loss = model.loss_fn(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "Epoch [1/100], Loss: 1.0425273291766644\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "Epoch [2/100], Loss: 0.9003364369273186\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "shapelet distance shape: torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "Epoch [3/100], Loss: 0.7775783389806747\n",
      "torch.Size([4, 240])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m ShapletLearner(num_shapelets, shapelet_lengths, input_size, num_classes, alpha, kmeans_centroids, type_dist\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDTW\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m## Add higher regularization after the new method\u001b[39;00m\n\u001b[0;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain_shaplet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[92], line 12\u001b[0m, in \u001b[0;36mtrain_shaplet_model\u001b[1;34m(model, train_loader, optimizer, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m time_series, labels \u001b[38;5;241m=\u001b[39m time_series\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_series\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss_fn(predictions, labels)\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[101], line 80\u001b[0m, in \u001b[0;36mShapletLearner.forward\u001b[1;34m(self, ts)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ts):\n\u001b[0;32m     79\u001b[0m     ts \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 80\u001b[0m     shaplet_distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_shapelet_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapelet distance shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, shaplet_distances\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     82\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(shaplet_distances)\n",
      "Cell \u001b[1;32mIn[101], line 64\u001b[0m, in \u001b[0;36mShapletLearner._compute_shapelet_dist\u001b[1;34m(self, ts)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_segments):\n\u001b[0;32m     63\u001b[0m     segment \u001b[38;5;241m=\u001b[39m ts[:, j:j\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK]\n\u001b[1;32m---> 64\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mDTW_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapelet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(dist)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNan Detected in DTW distance calculation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[75], line 20\u001b[0m, in \u001b[0;36mDTW_calc\u001b[1;34m(ts1, ts2)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mComputes the DTW similarity (for univariate time series) between two time series.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mHandles one input having batch size 1 for broadcasting (shapelet of shape (1, len_shapelet)).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mdtw_dist: Tensor of shape (batch_size,) containing the DTW distance for each batch.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Compute the cost matrix\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m cost_mat \u001b[38;5;241m=\u001b[39m \u001b[43mcost_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Return the square root of the final element in the cost matrix (total DTW cost for each batch)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msqrt(cost_mat[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[75], line 65\u001b[0m, in \u001b[0;36mcost_matrix\u001b[1;34m(ts1, ts2)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, ts1_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, ts2_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 65\u001b[0m         cost \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m         cum_sum[:, i, j] \u001b[38;5;241m=\u001b[39m cost \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[0;32m     67\u001b[0m             cum_sum[:, i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, j],   \u001b[38;5;66;03m# Insertion\u001b[39;00m\n\u001b[0;32m     68\u001b[0m             cum_sum[:, i, j \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m],   \u001b[38;5;66;03m# Deletion\u001b[39;00m\n\u001b[0;32m     69\u001b[0m             cum_sum[:, i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, j \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Match\u001b[39;00m\n\u001b[0;32m     70\u001b[0m         ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cum_sum[:, \u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:]\n",
      "Cell \u001b[1;32mIn[75], line 37\u001b[0m, in \u001b[0;36meuclidean_diff\u001b[1;34m(ts1, ts2)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_diff\u001b[39m(ts1, ts2):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Calculates the squared Euclidean distance between two points (or vectors) from two univariate time series.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Handles broadcasting if one input has batch size 1 (shapelet of shape (1,)).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    dist: Tensor of shape (batch_size,) containing the squared Euclidean distance for each batch.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mts1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = None\n",
    "trial = TSDataset(ts_data = ts_data[:16, :], labels=labels[0:16])\n",
    "train_loader = DataLoader(trial, batch_size=4, shuffle=True)\n",
    "\n",
    "kmeans_centroids = shapelet_initialization(ts_data, num_shapelets, shapelet_lengths)\n",
    "\n",
    "model = ShapletLearner(num_shapelets, shapelet_lengths, input_size, num_classes, alpha, kmeans_centroids, type_dist= \"DTW\") ## Add higher regularization after the new method\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_shaplet_model(model, train_loader, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 240])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 240])\n",
      "tensor([[15.6726,  1.2704,  0.3885, 96.5818,  0.5385, 22.9997, 13.7396, 15.6939,\n",
      "         11.9448,  0.3282],\n",
      "        [12.3254,  0.4494,  5.1173, 20.4109,  0.8788,  9.9148,  0.2192,  2.0188,\n",
      "          7.9067,  1.1923],\n",
      "        [16.5867,  4.5312,  7.0887, 90.1261,  1.2202, 62.1220,  6.4220,  0.7521,\n",
      "          4.9750,  6.1174],\n",
      "        [11.0426,  1.3848,  0.1630,  9.6199,  1.1684, 24.3661,  2.1627, 15.4974,\n",
      "          7.1689,  1.5160]], grad_fn=<StackBackward0>)\n",
      "torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "tensor([[ 16.6702,  71.4301,   0.6279, 111.3880, 109.5882,  29.6262,  12.7812,\n",
      "           9.0412,   2.1144,   2.2880],\n",
      "        [  7.0867,  19.3994,   2.1259,  49.5830,   7.4677,  25.1255,  15.9521,\n",
      "           3.9812,   5.4962,   9.9307],\n",
      "        [  2.5336,  98.7297,   0.2673,  15.3266, 157.4226,  36.4711,   3.2270,\n",
      "          12.1620,  44.3647,   2.8743],\n",
      "        [  8.9942,  22.5297,   1.0492,  44.9464,   7.1790,  15.3946,  17.5222,\n",
      "           3.4425,   3.5099,   4.1384]], grad_fn=<StackBackward0>)\n",
      "torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 240])\n",
      "tensor([[  5.5912,  43.1362,   0.4292,  49.7692, 114.3601,   1.3540,   0.4735,\n",
      "           9.2781,  39.4748,   1.9139],\n",
      "        [  6.8510,   2.5943,   1.8933,  17.9452,   5.5333,   6.1212,   0.3783,\n",
      "          13.7501,   7.8971,   1.3894],\n",
      "        [  5.1827,   9.7634,   4.6723,  26.0217,  53.6907,  19.5390,   1.4645,\n",
      "           5.0365,  56.3323,   5.8050],\n",
      "        [ 11.2726,  22.3277,   1.8204, 139.6992,   2.7475,  19.6443,   2.3650,\n",
      "           2.3174,   5.3359,   0.6083]], grad_fn=<StackBackward0>)\n",
      "torch.Size([4, 10])\n",
      "torch.Size([4, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m ShapletLearner(num_shapelets, shapelet_lengths, input_size, num_classes, alpha, kmeans_centroids, type_dist\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m## Add higher regularization after the new method\u001b[39;00m\n\u001b[0;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain_shaplet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[92], line 14\u001b[0m, in \u001b[0;36mtrain_shaplet_model\u001b[1;34m(model, train_loader, optimizer, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(time_series)\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss_fn(predictions, labels)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     16\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = None\n",
    "trial = TSDataset(ts_data[:16, :], labels=labels[0:16])\n",
    "train_loader = DataLoader(trial, batch_size=4, shuffle=True)\n",
    "\n",
    "kmeans_centroids = shapelet_initialization(ts_data, num_shapelets, shapelet_lengths)\n",
    "\n",
    "model = ShapletLearner(num_shapelets, shapelet_lengths, input_size, num_classes, alpha, kmeans_centroids, type_dist= \"euclid\") ## Add higher regularization after the new method\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_shaplet_model(model, train_loader, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33656\\1443490878.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  plt.plot(torch.tensor(model.shapelets[6][0]))  ## I'll Try to make it match with the timeseries later\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee3490a7e0>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting the shapelets is easy\n",
    "\n",
    "plt.plot(torch.tensor(model.shapelets[6][0]))  ## I'll Try to make it match with the timeseries later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (1): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (2): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (3): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (4): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (5): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (6): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (7): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (8): Parameter containing: [torch.float32 of size 1x10]\n",
       "    (9): Parameter containing: [torch.float32 of size 1x10]\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 80.0944,  79.8535,  81.6252,  85.9091,  92.5682, 101.4552, 111.5973,\n",
       "        121.8285, 131.0759, 138.5772], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DTW import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2247)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW Distance: 2.291287899017334\n",
      "Gradient for ts1: tensor([[-0.2182,  0.8729],\n",
      "        [-0.2182, -0.2182],\n",
      "        [-0.2182, -0.2182]])\n"
     ]
    }
   ],
   "source": [
    "ts1 = torch.tensor([[1.0, 4.5], [2.0, 3.0], [3.0, 4.0]], requires_grad=True)\n",
    "ts2 = torch.tensor([[1.5, 2.5], [2.5, 3.5], [3.5, 4.5]])\n",
    "\n",
    "dtw_distance = DTW_calc(ts1, ts2)\n",
    "\n",
    "# Compute gradients\n",
    "dtw_distance.backward()\n",
    "\n",
    "print(\"DTW Distance:\", dtw_distance.item())\n",
    "print(\"Gradient for ts1:\", ts1.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
